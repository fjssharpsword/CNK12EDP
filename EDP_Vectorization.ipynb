{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py:200: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "from itertools import compress\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import json\n",
    "from bert_serving.client import BertClient\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image  \n",
    "import ftplib\n",
    "import time\n",
    "import threading\n",
    "\n",
    "#1.加载训练文件\n",
    "with open(\"/data/fjs/data/math/math.json\",'r') as load_f:\n",
    "    allItems = json.load(load_f)#list中条目是dict\n",
    "    \n",
    "#2.探索性数据分析EDA\n",
    "#2.1 习题难度分布\n",
    "diffs={}#统计难度类别\n",
    "for item in allItems:\n",
    "    diff = item['qdiff'] #获取习题难度\n",
    "    diffs[diff]=diffs.get(diff,0)+1 #统计每个元素出现的个数。\n",
    "#{0: 9, 1: 5434, 2: 198597, 3: 482016, 4: 212266, 5: 1678}\n",
    "df = pd.DataFrame(diffs,index=[0])\n",
    "df.plot(kind='bar')\n",
    "plt.show()\n",
    "#2.2 习题概念分布\n",
    "cons={}#统计概念类别\n",
    "for item in allItems:\n",
    "    con =item['qklg']\n",
    "    conp = con.split(',')#逗号分隔\n",
    "    for p in conp:#具体概念点\n",
    "        cons[p]=cons.get(p,0)+1\n",
    "df = pd.DataFrame(list(cons.items()))\n",
    "print (df.shape[0])#知识点数\n",
    "print (np.mean(df.loc[:,1]))#知识点数的均值\n",
    "#绘制箱形图\n",
    "def drawBox(freqs):\n",
    "    #创建箱形图\n",
    "    #第一个参数为待绘制的定量数据\n",
    "    #第二个参数为数据的文字说明\n",
    "    plt.boxplot([freqs], labels=['Concepts'])\n",
    "    plt.title('Frequecy Of Concpets')\n",
    "    plt.show()\n",
    "drawBox(df.loc[:,1])\n",
    "\n",
    "#3.习题的文本、概念基于BERT模型Embedding；习题的图像基于Resnet模型提取视觉特征\n",
    "f = ftplib.FTP(\"10.21.3.24\")  # 实例化FTP对象\n",
    "f.login(\"ftpuser\", \"dm2019\")  # 登录\n",
    "def ftp_download(remotename,localname):\n",
    "    bufsize = 1024  # 设置缓冲器大小\n",
    "    fp = open(localname, 'wb')\n",
    "    f.retrbinary('RETR %s' % remotename, fp.write, bufsize)\n",
    "    fp.close()\n",
    "#预训练resnet50模型\n",
    "transform1 = transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()])\n",
    "resnet50_feature_extractor = models.resnet50(pretrained = True)\n",
    "resnet50_feature_extractor.fc = nn.Linear(2048, 2048)\n",
    "torch.nn.init.eye(resnet50_feature_extractor.fc.weight)\n",
    "for param in resnet50_feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "#定义18个线程提取特征，每个线程提取5万条\n",
    "def threadFunction(n,items):\n",
    "    print (\"Start Threading %d.\"%n)\n",
    "    start = time.time()\n",
    "    VItems = []#保存列表\n",
    "    for item in items:\n",
    "        VItem={}#dict\n",
    "        VItem['quid']=item['quid']\n",
    "        VItem['qdiff']=item['qdiff']\n",
    "        #3.1 文本、概念embedding\n",
    "        texts=item['qtext']#list\n",
    "        strtext=''\n",
    "        for text in texts:\n",
    "            strtext=strtext+text\n",
    "        concepts=item['qklg']\n",
    "        bc = BertClient()#连接BERT Server\n",
    "        VItem['qtext']=bc.encode([strtext])[0]#list,768长度\n",
    "        VItem['qklg']=bc.encode([concepts])[0]#list，768长度\n",
    "        #3.2 图片视觉特征提取\n",
    "        images=[]\n",
    "        for imgftppath in item['qimage']:\n",
    "            imgftppath = imgftppath[17:]#截掉ftp://10.21.3.24/\n",
    "            imglocalpath = \"/data/fjs/data/imgs/\"+imgftppath.split(\"/\")[-1]\n",
    "            ftp_download(imgftppath,imglocalpath)#从ftp下载到本地\n",
    "            image = Image.open(imglocalpath)#打开本地图片\n",
    "            images.append(image)\n",
    "        #多图拼接成一张长图\n",
    "        if len(images)==0:\n",
    "            VItem['qimage']=np.zeros(2048)\n",
    "        else:\n",
    "            width,height=images[0].size\n",
    "            for image in images:\n",
    "                w,h = image.size\n",
    "                if w>width:width=w\n",
    "                if h>height: height=h\n",
    "            longImg =  Image.new(images[0].mode,(width,height*len(images)))\n",
    "            for i,im in enumerate(images):\n",
    "                longImg.paste(im,box=(0,i*height))\n",
    "            #长图向量化    \n",
    "            imgarr = np.array(longImg)\n",
    "            if imgarr.shape[2] == 4: #四通道转为三通道\n",
    "                img1 = longImg.convert(\"RGB\")\n",
    "            #img = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "            img2 = transform1(img1)\n",
    "            x = Variable(torch.unsqueeze(img2, dim=0).float(), requires_grad=False)\n",
    "            y = resnet50_feature_extractor(x)\n",
    "            y = y.data.numpy()\n",
    "            VItem['qimage']=y #2048长度\n",
    "        VItems.append(VItem)\n",
    "    with open(\"/data/fjs/data/math/mathV\"+str(n)+\".json\",\"w\") as dump_f:\n",
    "        json.dump(VItems,dump_f)#保存到json文件\n",
    "    print ('file %d saved.'%n)\n",
    "    end = time.time()\n",
    "    print (\"Complete time: %f s\" % (end - start))\n",
    "\n",
    "#将全部90万条记录分成18份提取特征\n",
    "for i in range(0,len(allItems),50000):\n",
    "    mThread = threading.Thread(target=threadFunction, args=(i,allItems[i:i+50000]))\n",
    "    mThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import json \n",
    "import ftplib\n",
    "from pathlib import Path\n",
    "#1.加载训练文件\n",
    "with open(\"/data/fjs/data/math/math.json\",'r') as load_f:\n",
    "    allItems = json.load(load_f)#list中条目是dict\n",
    "    \n",
    "#count =0\n",
    "f = ftplib.FTP(\"10.21.3.24\")  # 实例化FTP对象\n",
    "f.login(\"ftpuser\", \"dm2019\")  # 登录\n",
    "def ftp_download(remotename,localname):\n",
    "    bufsize = 1024  # 设置缓冲器大小\n",
    "    fp = open(localname, 'wb')\n",
    "    f.retrbinary('RETR %s' % remotename, fp.write, bufsize)\n",
    "    fp.close()\n",
    "#将ftp全部手动在操作系统上下载到本地，然后再调整异常的，减少磁盘IO和网络传输时间\n",
    "imgs=[]\n",
    "for item in allItems:\n",
    "    for img in item['qimage']:\n",
    "        #if img.find('ftp://10.21.3.24/')==-1:print (img)\n",
    "        #if img.find('upimages')==-1:print (img)\n",
    "        ipath = img[img.find('upimages'):]#截取ftp://10.21.3.24/tiku/images/后的目录\n",
    "        ipath = \"/data/fjs/data/mathimgs/\"+ ipath\n",
    "        #if img.find('\\\\')>=0:img = img[:-1] #去除最后一个字符\n",
    "        if ipath.find('\\\\')>=0:ipath = ipath[:-1] #去除最后一个字符\n",
    "        if not os.path.exists(ipath):#本地不存在，去下载。\n",
    "            img = img[17:]#截掉ftp://10.21.3.24/\n",
    "            imgs.append(img)\n",
    "for img in imgs:\n",
    "    ipath = img[img.find('upimages'):]\n",
    "    ipath = \"/data/fjs/data/mathimgs/\"+ ipath\n",
    "    ftp_download(img,ipath)#从ftp下载到本地 \n",
    "    print (ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900000, 5)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "#将list中dict的json文件转化为DataFrame并保存为CSV，可以利用python的矩阵计算优势，而不是采用循环\n",
    "with open(\"/data/fjs/data/math/math.json\",'r') as load_f:\n",
    "    allItems = json.load(load_f)#list中条目是dict\n",
    "csvlist=[]\n",
    "for item in allItems:\n",
    "    strtext=''\n",
    "    for text in item['qtext']: strtext=strtext+text\n",
    "    strimage=''\n",
    "    for image in item['qimage']:strimage=strimage+\",\"+image\n",
    "    tmplist=[item['quid'],item['qdiff'],item['qklg'], strtext, strimage]\n",
    "    csvlist.append(tmplist)\n",
    "df = pd.DataFrame(csvlist, columns=['quid', 'qdiff', 'qklg','qtext','qimage']) \n",
    "print (df.shape)\n",
    "df.to_csv('/data/fjs/data/math/math.csv',index=False,sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234921, 5)\n"
     ]
    }
   ],
   "source": [
    "#去除空置，在多模态学习上更有意义。\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"/data/fjs/data/math/math.csv\",sep='|') #print (data.head())\n",
    "data=data.dropna(axis=0,how='any')#删除包含空置的行，主要是没有图片。\n",
    "#data = data.fillna('none')\n",
    "print (data.shape)\n",
    "#print (data.head())\n",
    "data.to_csv('/data/fjs/data/math/mathmin.csv',index=False,sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py:200: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.eye is now deprecated in favor of nn.init.eye_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234921 rows and 5 cols\n",
      "5 rows and 772 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjs/.local/lib/python3.5/site-packages/bert_serving/client/__init__.py:277: UserWarning: server does not put a restriction on \"max_seq_len\", it will determine \"max_seq_len\" dynamically according to the sequences in the batch. you can restrict the sequence length on the client side for better efficiency\n",
      "  warnings.warn('server does not put a restriction on \"max_seq_len\", '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows and 1539 cols\n",
      "5 rows and 3586 cols\n",
      "Complete time: 6.398251 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from bert_serving.client import BertClient\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models,transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "#1.预训练resnet50模型构建\n",
    "transform1 = transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()])\n",
    "resnet50_feature_extractor = models.resnet50(pretrained = True)\n",
    "resnet50_feature_extractor.fc = nn.Linear(2048, 2048)\n",
    "torch.nn.init.eye(resnet50_feature_extractor.fc.weight)\n",
    "for param in resnet50_feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "#2.连接BertService\n",
    "bc = BertClient()#连接BERT Server\n",
    "\n",
    "#3.多图拼接长图并向量化函数定义\n",
    "def fn_ImageToVec(x):\n",
    "    images=[]\n",
    "    for img in x.split(\",\")[1:]:#ftp图片用逗号隔开\n",
    "        try:\n",
    "            if img.find('\\\\'): img=img.replace('\\\\','')\n",
    "            ipath = img[img.find('upimages'):]#截取ftp://10.21.3.24/tiku/images/后的目录\n",
    "            ipath = \"/data/fjs/data/mathimgs/\"+ ipath\n",
    "            image = Image.open(ipath)#打开本地图片\n",
    "            images.append(image)\n",
    "        except OSError:pass\n",
    "        continue\n",
    "    if len(images)==0:return np.zeros((1,2048))\n",
    "    else:\n",
    "        #多图拼接成一张长图\n",
    "        width,height=images[0].size\n",
    "        for image in images:\n",
    "            w,h = image.size\n",
    "            if w>width:width=w\n",
    "            if h>height: height=h\n",
    "        longImg =  Image.new(images[0].mode,(width,height*len(images)))\n",
    "        for i,im in enumerate(images):\n",
    "            longImg.paste(im,box=(0,i*height))\n",
    "        #长图向量化    \n",
    "        imgarr = np.array(longImg)\n",
    "        if imgarr.shape[2] == 4: #四通道转为三通道\n",
    "            longImg = longImg.convert(\"RGB\")\n",
    "        longImg = transform1(longImg)\n",
    "        x = Variable(torch.unsqueeze(longImg, dim=0).float(), requires_grad=False)\n",
    "        y = resnet50_feature_extractor(x)\n",
    "        return y.data.numpy() #2048长度\n",
    "\n",
    "start = time.time()    \n",
    "#4.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjs/data/math/mathmin.csv\",sep='|') \n",
    "print (\"%d rows and %d cols\"%(data.shape[0],data.shape[1]))\n",
    "#data = data.head()\n",
    "#5.1概念向量化\n",
    "vecklg = bc.encode(data['qklg'].tolist())\n",
    "data = pd.concat([data,pd.DataFrame(vecklg)],axis=1)#768维\n",
    "data=data.drop(['qklg'], axis=1)\n",
    "print (\"%d rows and %d cols\"%(data.shape[0],data.shape[1]))\n",
    "#5.2文本向量化\n",
    "vectxt = data['qtext'].apply(lambda x: bc.encode([x])[0])\n",
    "data = pd.concat([data,pd.DataFrame(vectxt.tolist())],axis=1)#768维\n",
    "data=data.drop(['qtext'], axis=1)\n",
    "print (\"%d rows and %d cols\"%(data.shape[0],data.shape[1]))\n",
    "#5.3 图像向量化\n",
    "npvimg=data['qimage'].apply(lambda x: fn_ImageToVec(x)[0])\n",
    "data = pd.concat([data,pd.DataFrame(npvimg.tolist())],axis=1)#2048维\n",
    "data=data.drop(['qimage'], axis=1)\n",
    "print (\"%d rows and %d cols\"%(data.shape[0],data.shape[1]))\n",
    "#6.保存向量化后的文件\n",
    "data.to_csv(\"/data/fjs/data/math/mathV.csv\",index=False,sep='|')\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py:200: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.eye is now deprecated in favor of nn.init.eye_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234921 rows and 5 cols\n",
      "(100, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjs/.local/lib/python3.5/site-packages/bert_serving/client/__init__.py:277: UserWarning: server does not put a restriction on \"max_seq_len\", it will determine \"max_seq_len\" dynamically according to the sequences in the batch. you can restrict the sequence length on the client side for better efficiency\n",
      "  warnings.warn('server does not put a restriction on \"max_seq_len\", '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 rows and 3586 cols\n",
      "file 0 Complete time: 37.075272 s\n",
      "(100, 5)\n",
      "200 rows and 3586 cols\n",
      "file 100 Complete time: 35.891687 s\n",
      "(100, 5)\n",
      "300 rows and 3586 cols\n",
      "file 200 Complete time: 36.220275 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 300 Complete time: 36.650671 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 400 Complete time: 37.623131 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 500 Complete time: 36.507936 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 600 Complete time: 36.622813 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 700 Complete time: 37.806572 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 800 Complete time: 38.063151 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 900 Complete time: 37.046798 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1000 Complete time: 37.863056 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1100 Complete time: 37.595042 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1200 Complete time: 37.377395 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1300 Complete time: 37.677139 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1400 Complete time: 37.411739 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1500 Complete time: 37.037095 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1600 Complete time: 38.628680 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1700 Complete time: 38.051427 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1800 Complete time: 37.283699 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 1900 Complete time: 38.023294 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2000 Complete time: 38.924130 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2100 Complete time: 36.851672 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2200 Complete time: 38.498261 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2300 Complete time: 37.857881 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2400 Complete time: 38.620873 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2500 Complete time: 36.918600 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2600 Complete time: 38.511781 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2700 Complete time: 38.755736 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2800 Complete time: 37.320504 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 2900 Complete time: 37.022771 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3000 Complete time: 38.263737 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3100 Complete time: 36.636150 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3200 Complete time: 37.694156 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3300 Complete time: 37.487472 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3400 Complete time: 37.512797 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3500 Complete time: 38.783974 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3600 Complete time: 37.942926 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3700 Complete time: 37.105071 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3800 Complete time: 37.750887 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 3900 Complete time: 38.417971 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4000 Complete time: 37.139745 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4100 Complete time: 37.322414 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4200 Complete time: 37.757502 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4300 Complete time: 38.043897 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4400 Complete time: 38.764603 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4500 Complete time: 36.676455 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4600 Complete time: 37.415783 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4700 Complete time: 37.421805 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4800 Complete time: 36.867578 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 4900 Complete time: 36.891406 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5000 Complete time: 37.721907 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5100 Complete time: 37.925856 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5200 Complete time: 37.546406 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5300 Complete time: 38.268965 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5400 Complete time: 38.007288 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5500 Complete time: 37.785192 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5600 Complete time: 38.287554 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5700 Complete time: 37.817171 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5800 Complete time: 38.312357 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 5900 Complete time: 37.111265 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6000 Complete time: 37.064469 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6100 Complete time: 38.362783 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6200 Complete time: 38.309326 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6300 Complete time: 37.545859 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6400 Complete time: 37.250145 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6500 Complete time: 37.262490 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6600 Complete time: 38.163954 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6700 Complete time: 38.138602 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6800 Complete time: 37.358882 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 6900 Complete time: 38.088085 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7000 Complete time: 38.313376 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7100 Complete time: 38.224341 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7200 Complete time: 37.580393 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7300 Complete time: 38.109030 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7400 Complete time: 37.913926 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7500 Complete time: 38.767336 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7600 Complete time: 37.664399 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7700 Complete time: 38.959225 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7800 Complete time: 38.227577 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 7900 Complete time: 37.376859 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8000 Complete time: 38.210703 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8100 Complete time: 37.741297 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8200 Complete time: 37.712851 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8300 Complete time: 37.335906 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8400 Complete time: 37.803504 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8500 Complete time: 38.437880 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8600 Complete time: 38.771699 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8700 Complete time: 38.078976 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8800 Complete time: 37.334699 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 8900 Complete time: 37.837373 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9000 Complete time: 37.571330 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9100 Complete time: 37.541862 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9200 Complete time: 37.843358 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9300 Complete time: 38.304457 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9400 Complete time: 38.740255 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9500 Complete time: 37.980403 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9600 Complete time: 38.026166 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9700 Complete time: 38.991110 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9800 Complete time: 37.945887 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 9900 Complete time: 36.836709 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10000 Complete time: 37.907512 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10100 Complete time: 38.589380 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10200 Complete time: 38.074094 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10300 Complete time: 38.018784 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10400 Complete time: 37.097813 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10500 Complete time: 37.954709 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10600 Complete time: 39.046922 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10700 Complete time: 37.186104 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10800 Complete time: 38.554389 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 10900 Complete time: 38.967099 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11000 Complete time: 38.175693 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11100 Complete time: 38.791190 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11200 Complete time: 38.108311 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11300 Complete time: 37.219871 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11400 Complete time: 37.484532 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11500 Complete time: 38.277232 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11600 Complete time: 38.351439 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11700 Complete time: 38.166193 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 11800 Complete time: 36.936596 s\n",
      "(100, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 rows and 3586 cols\n",
      "file 11900 Complete time: 38.362356 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12000 Complete time: 38.038853 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12100 Complete time: 37.127180 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12200 Complete time: 38.469965 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12300 Complete time: 38.399041 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12400 Complete time: 37.201553 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12500 Complete time: 37.412860 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12600 Complete time: 38.898150 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12700 Complete time: 38.171540 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12800 Complete time: 37.668962 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 12900 Complete time: 38.832823 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13000 Complete time: 37.919673 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13100 Complete time: 37.064829 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13200 Complete time: 37.607529 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13300 Complete time: 37.990244 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13400 Complete time: 37.665525 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13500 Complete time: 37.792756 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13600 Complete time: 37.138120 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13700 Complete time: 37.866215 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13800 Complete time: 38.196446 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 13900 Complete time: 39.222113 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14000 Complete time: 38.038437 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14100 Complete time: 37.325885 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14200 Complete time: 38.498197 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14300 Complete time: 37.577728 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14400 Complete time: 37.959811 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14500 Complete time: 39.292394 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14600 Complete time: 37.821498 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14700 Complete time: 37.577748 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14800 Complete time: 39.061299 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 14900 Complete time: 38.770461 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15000 Complete time: 36.867557 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15100 Complete time: 37.936796 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15200 Complete time: 37.673493 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15300 Complete time: 37.750776 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15400 Complete time: 37.807380 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15500 Complete time: 38.421436 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15600 Complete time: 37.265816 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15700 Complete time: 37.161974 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15800 Complete time: 38.206053 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 15900 Complete time: 38.591142 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16000 Complete time: 39.000718 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16100 Complete time: 37.379282 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16200 Complete time: 37.834330 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16300 Complete time: 37.553527 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16400 Complete time: 37.027165 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16500 Complete time: 37.654938 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16600 Complete time: 38.377706 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16700 Complete time: 37.885702 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16800 Complete time: 38.606397 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 16900 Complete time: 37.750648 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17000 Complete time: 37.647484 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17100 Complete time: 39.239644 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17200 Complete time: 38.029376 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17300 Complete time: 38.123966 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17400 Complete time: 37.539999 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17500 Complete time: 38.897898 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17600 Complete time: 38.022511 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17700 Complete time: 38.711147 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17800 Complete time: 37.636169 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 17900 Complete time: 37.151397 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18000 Complete time: 38.564015 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18100 Complete time: 38.574088 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18200 Complete time: 38.678024 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18300 Complete time: 37.766648 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18400 Complete time: 37.896617 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18500 Complete time: 37.643160 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18600 Complete time: 38.507338 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18700 Complete time: 38.142385 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18800 Complete time: 37.577721 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 18900 Complete time: 37.306849 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19000 Complete time: 38.487013 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19100 Complete time: 38.772336 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19200 Complete time: 38.506948 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19300 Complete time: 38.493208 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19400 Complete time: 39.015237 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19500 Complete time: 37.631846 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19600 Complete time: 37.801600 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19700 Complete time: 37.975930 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19800 Complete time: 38.444012 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 19900 Complete time: 37.987177 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20000 Complete time: 37.532036 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20100 Complete time: 38.356961 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20200 Complete time: 37.830011 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20300 Complete time: 37.129076 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20400 Complete time: 38.105075 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20500 Complete time: 37.403102 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20600 Complete time: 38.201860 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20700 Complete time: 37.637554 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20800 Complete time: 38.172964 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 20900 Complete time: 37.818977 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21000 Complete time: 38.074218 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21100 Complete time: 37.769493 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21200 Complete time: 38.197031 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21300 Complete time: 37.184076 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21400 Complete time: 37.936392 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21500 Complete time: 38.841085 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21600 Complete time: 38.204488 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21700 Complete time: 37.892327 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21800 Complete time: 38.155931 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 21900 Complete time: 37.902964 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22000 Complete time: 37.534054 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22100 Complete time: 37.964385 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22200 Complete time: 38.047121 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22300 Complete time: 38.277868 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22400 Complete time: 37.964720 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22500 Complete time: 38.103605 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22600 Complete time: 38.774743 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22700 Complete time: 37.943055 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22800 Complete time: 37.715990 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 22900 Complete time: 38.595584 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23000 Complete time: 38.386938 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23100 Complete time: 39.861050 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23200 Complete time: 37.859526 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23300 Complete time: 38.581582 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23400 Complete time: 37.581063 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23500 Complete time: 37.528728 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 23600 Complete time: 37.698776 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23700 Complete time: 37.851984 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23800 Complete time: 38.211184 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 23900 Complete time: 37.287200 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24000 Complete time: 37.663622 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24100 Complete time: 38.388363 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24200 Complete time: 37.685282 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24300 Complete time: 39.403898 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24400 Complete time: 39.242910 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24500 Complete time: 37.932128 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24600 Complete time: 38.240420 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24700 Complete time: 37.515737 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24800 Complete time: 37.266226 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 24900 Complete time: 38.316552 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25000 Complete time: 37.731390 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25100 Complete time: 37.698747 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25200 Complete time: 37.617985 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25300 Complete time: 38.275537 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25400 Complete time: 38.894242 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25500 Complete time: 37.477952 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25600 Complete time: 37.673958 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25700 Complete time: 38.014910 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25800 Complete time: 38.149642 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 25900 Complete time: 38.092057 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26000 Complete time: 38.101779 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26100 Complete time: 38.283990 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26200 Complete time: 37.598468 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26300 Complete time: 37.347471 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26400 Complete time: 37.188403 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26500 Complete time: 37.614548 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26600 Complete time: 37.445866 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26700 Complete time: 38.086327 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26800 Complete time: 38.043941 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 26900 Complete time: 38.333832 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27000 Complete time: 37.689375 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27100 Complete time: 38.352921 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27200 Complete time: 37.951209 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27300 Complete time: 38.632258 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27400 Complete time: 37.575778 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27500 Complete time: 37.923713 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27600 Complete time: 37.875506 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27700 Complete time: 38.848698 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27800 Complete time: 37.599253 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 27900 Complete time: 38.562982 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28000 Complete time: 37.424259 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28100 Complete time: 37.500369 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28200 Complete time: 37.783779 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28300 Complete time: 37.591106 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28400 Complete time: 38.178535 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28500 Complete time: 38.134271 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28600 Complete time: 37.625287 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28700 Complete time: 38.003456 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28800 Complete time: 37.743109 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 28900 Complete time: 38.645774 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29000 Complete time: 38.001878 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29100 Complete time: 39.080610 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29200 Complete time: 39.072528 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29300 Complete time: 38.194029 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29400 Complete time: 38.798977 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29500 Complete time: 37.402109 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29600 Complete time: 37.674424 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29700 Complete time: 38.388628 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29800 Complete time: 39.181908 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 29900 Complete time: 37.974460 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30000 Complete time: 37.527169 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30100 Complete time: 37.997003 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30200 Complete time: 38.468161 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30300 Complete time: 38.411604 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30400 Complete time: 38.271389 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30500 Complete time: 37.999037 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30600 Complete time: 38.104602 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30700 Complete time: 38.235428 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30800 Complete time: 37.401723 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 30900 Complete time: 37.696774 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31000 Complete time: 37.515974 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31100 Complete time: 37.209672 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31200 Complete time: 37.415422 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31300 Complete time: 37.639292 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31400 Complete time: 38.461071 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31500 Complete time: 39.427313 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31600 Complete time: 38.359310 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31700 Complete time: 39.294548 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31800 Complete time: 37.892891 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 31900 Complete time: 37.646955 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32000 Complete time: 38.042741 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32100 Complete time: 38.029619 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32200 Complete time: 38.606574 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32300 Complete time: 38.808299 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32400 Complete time: 38.907793 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32500 Complete time: 37.037878 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32600 Complete time: 37.938071 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32700 Complete time: 36.724056 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32800 Complete time: 38.181876 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 32900 Complete time: 36.721959 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33000 Complete time: 36.798944 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33100 Complete time: 37.204057 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33200 Complete time: 37.007776 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33300 Complete time: 37.051611 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33400 Complete time: 38.012525 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33500 Complete time: 36.537880 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33600 Complete time: 37.539895 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33700 Complete time: 37.258935 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33800 Complete time: 37.428284 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 33900 Complete time: 36.828282 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34000 Complete time: 36.841624 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34100 Complete time: 36.939383 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34200 Complete time: 37.238029 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34300 Complete time: 37.210667 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34400 Complete time: 37.194407 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34500 Complete time: 36.825574 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34600 Complete time: 37.514407 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34700 Complete time: 36.918031 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34800 Complete time: 37.139456 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 34900 Complete time: 37.113298 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35000 Complete time: 37.161589 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35100 Complete time: 36.916697 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35200 Complete time: 37.276938 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35300 Complete time: 36.990053 s\n",
      "(100, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 rows and 3586 cols\n",
      "file 35400 Complete time: 36.817555 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35500 Complete time: 37.494774 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35600 Complete time: 36.862209 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35700 Complete time: 37.691097 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35800 Complete time: 37.508337 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 35900 Complete time: 36.673535 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36000 Complete time: 37.286995 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36100 Complete time: 36.959913 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36200 Complete time: 37.272139 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36300 Complete time: 36.561517 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36400 Complete time: 36.720494 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36500 Complete time: 36.976093 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36600 Complete time: 36.751439 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36700 Complete time: 37.448492 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36800 Complete time: 37.001312 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 36900 Complete time: 37.314265 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 37000 Complete time: 37.324909 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 37100 Complete time: 36.746011 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 37200 Complete time: 37.049233 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 37300 Complete time: 37.391799 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 37400 Complete time: 36.729794 s\n",
      "(100, 5)\n",
      "400 rows and 3586 cols\n",
      "file 37500 Complete time: 37.505988 s\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from bert_serving.client import BertClient\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models,transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "#1.预训练resnet50模型构建\n",
    "transform1 = transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()])\n",
    "resnet50_feature_extractor = models.resnet50(pretrained = True)\n",
    "resnet50_feature_extractor.fc = nn.Linear(2048, 2048)\n",
    "torch.nn.init.eye(resnet50_feature_extractor.fc.weight)\n",
    "for param in resnet50_feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "#2.连接BertService\n",
    "bc = BertClient()#连接BERT Server\n",
    "\n",
    "#3.多图拼接长图并向量化函数定义\n",
    "def fn_ImageToVec(x):\n",
    "    images=[]\n",
    "    for img in x.split(\",\")[1:]:#ftp图片用逗号隔开\n",
    "        if img.find('\\\\'): img=img.replace('\\\\','')\n",
    "        ipath = img[img.find('upimages'):]#截取ftp://10.21.3.24/tiku/images/后的目录\n",
    "        ipath = \"/data/fjs/data/mathimgs/\"+ ipath\n",
    "        image = Image.open(ipath)#打开本地图片\n",
    "        images.append(image)\n",
    "\n",
    "    if len(images)==0:return np.zeros((1,2048))\n",
    "    else:\n",
    "        #多图拼接成一张长图\n",
    "        width,height=images[0].size\n",
    "        for image in images:\n",
    "            w,h = image.size\n",
    "            if w>width:width=w\n",
    "            if h>height: height=h\n",
    "        longImg =  Image.new(images[0].mode,(width,height*len(images)))\n",
    "        for i,im in enumerate(images):\n",
    "            longImg.paste(im,box=(0,i*height))\n",
    "        #长图向量化    \n",
    "        imgarr = np.array(longImg)\n",
    "        if imgarr.shape[2] == 4: #四通道转为三通道\n",
    "            longImg = longImg.convert(\"RGB\")\n",
    "        longImg = transform1(longImg)\n",
    "        x = Variable(torch.unsqueeze(longImg, dim=0).float(), requires_grad=False)\n",
    "        y = resnet50_feature_extractor(x)\n",
    "        return y.data.numpy() #2048长度\n",
    "\n",
    "#4.加载训练文件\n",
    "dataIn = pd.read_csv(\"/data/fjs/data/math/mathmin.csv\",sep='|') \n",
    "print (\"%d rows and %d cols\"%(dataIn.shape[0],dataIn.shape[1]))\n",
    "\n",
    "for i in range(0,dataIn.shape[0],100):\n",
    "    try:\n",
    "        start = time.time() \n",
    "        data=dataIn[i:i+100]\n",
    "        print (data.shape)\n",
    "        #5.1概念向量化\n",
    "        vecklg = bc.encode(data['qklg'].tolist())\n",
    "        data = pd.concat([data,pd.DataFrame(vecklg)],axis=1)#768维\n",
    "        data=data.drop(['qklg'], axis=1)\n",
    "        #5.2文本向量化\n",
    "        vectxt = data['qtext'].apply(lambda x: bc.encode([str(x)])[0])\n",
    "        data = pd.concat([data,pd.DataFrame(vectxt.tolist())],axis=1)#768维\n",
    "        data=data.drop(['qtext'], axis=1)\n",
    "        #5.3 图像向量化\n",
    "        npvimg=data['qimage'].apply(lambda x: fn_ImageToVec(str(x))[0])\n",
    "        data = pd.concat([data,pd.DataFrame(npvimg.tolist())],axis=1)#2048维\n",
    "        data=data.drop(['qimage'], axis=1)\n",
    "        #6.保存向量化后的文件\n",
    "        print (\"%d rows and %d cols\"%(data.shape[0],data.shape[1]))\n",
    "        data.to_csv(\"/data/fjs/data/math/max/mathv\"+str(i)+\".csv\",index=False,sep='|')\n",
    "        end = time.time()\n",
    "        print (\"file %d Complete time: %f s\" % (i,(end - start)))\n",
    "    except Exception:pass\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
