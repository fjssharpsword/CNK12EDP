{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/data/fjs/data/dc_img'):\n",
    "    os.mkdir('/data/fjs/data/dc_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/fjs/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9.89M/9.91M [00:35<00:00, 359kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fjs/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0.00B [00:00, ?B/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/fjs/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/28.9k [00:00<?, ?B/s]\u001b[A\n",
      " 57%|█████▋    | 16.4k/28.9k [00:00<00:00, 65.6kB/s]\u001b[A\n",
      "32.8kB [00:00, 44.3kB/s]                            \u001b[A\n",
      "0.00B [00:00, ?B/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fjs/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/fjs/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.65M [00:00<?, ?B/s]\u001b[A\n",
      "  1%|          | 16.4k/1.65M [00:01<00:27, 59.7kB/s]\u001b[A\n",
      "  2%|▏         | 41.0k/1.65M [00:01<00:23, 67.7kB/s]\u001b[A\n",
      "  4%|▍         | 73.7k/1.65M [00:01<00:20, 78.2kB/s]\u001b[A\n",
      "  8%|▊         | 131k/1.65M [00:01<00:15, 99.0kB/s] \u001b[A\n",
      " 10%|▉         | 164k/1.65M [00:02<00:13, 107kB/s] \u001b[A\n",
      " 12%|█▏        | 197k/1.65M [00:02<00:12, 115kB/s]\u001b[A\n",
      " 14%|█▍        | 238k/1.65M [00:02<00:11, 127kB/s]\u001b[A\n",
      " 17%|█▋        | 279k/1.65M [00:02<00:10, 137kB/s]\u001b[A\n",
      " 20%|█▉        | 328k/1.65M [00:03<00:08, 151kB/s]\u001b[A\n",
      " 22%|██▏       | 369k/1.65M [00:03<00:08, 156kB/s]\u001b[A\n",
      " 25%|██▌       | 418k/1.65M [00:03<00:07, 166kB/s]\u001b[A\n",
      " 28%|██▊       | 459k/1.65M [00:03<00:07, 168kB/s]\u001b[A\n",
      " 31%|███       | 508k/1.65M [00:04<00:06, 176kB/s]\u001b[A\n",
      " 34%|███▍      | 557k/1.65M [00:04<00:05, 182kB/s]\u001b[A\n",
      " 35%|███▌      | 582k/1.65M [00:04<00:07, 145kB/s]\u001b[A\n",
      " 39%|███▉      | 639k/1.65M [00:04<00:06, 166kB/s]\u001b[A\n",
      " 41%|████      | 680k/1.65M [00:05<00:05, 164kB/s]\u001b[A\n",
      " 43%|████▎     | 705k/1.65M [00:05<00:07, 132kB/s]\u001b[A\n",
      " 45%|████▌     | 745k/1.65M [00:05<00:06, 145kB/s]\u001b[A\n",
      " 47%|████▋     | 770k/1.65M [00:05<00:06, 129kB/s]\u001b[A\n",
      " 49%|████▊     | 803k/1.65M [00:06<00:06, 130kB/s]\u001b[A\n",
      " 51%|█████     | 836k/1.65M [00:06<00:06, 130kB/s]\u001b[A\n",
      " 52%|█████▏    | 860k/1.65M [00:06<00:06, 122kB/s]\u001b[A\n",
      " 54%|█████▍    | 893k/1.65M [00:06<00:06, 125kB/s]\u001b[A\n",
      " 56%|█████▌    | 926k/1.65M [00:07<00:05, 128kB/s]\u001b[A\n",
      " 58%|█████▊    | 958k/1.65M [00:07<00:05, 130kB/s]\u001b[A\n",
      " 60%|██████    | 991k/1.65M [00:07<00:05, 131kB/s]\u001b[A\n",
      " 62%|██████▏   | 1.02M/1.65M [00:07<00:04, 132kB/s]\u001b[A\n",
      " 64%|██████▍   | 1.06M/1.65M [00:08<00:04, 133kB/s]\u001b[A\n",
      " 66%|██████▌   | 1.09M/1.65M [00:08<00:04, 133kB/s]\u001b[A\n",
      " 68%|██████▊   | 1.12M/1.65M [00:08<00:04, 131kB/s]\u001b[A\n",
      " 70%|███████   | 1.16M/1.65M [00:08<00:03, 132kB/s]\u001b[A\n",
      " 72%|███████▏  | 1.19M/1.65M [00:09<00:03, 133kB/s]\u001b[A\n",
      " 74%|███████▍  | 1.22M/1.65M [00:09<00:03, 136kB/s]\u001b[A\n",
      " 76%|███████▌  | 1.25M/1.65M [00:09<00:02, 136kB/s]\u001b[A\n",
      " 78%|███████▊  | 1.29M/1.65M [00:09<00:02, 154kB/s]\u001b[A\n",
      " 79%|███████▉  | 1.30M/1.65M [00:09<00:02, 146kB/s]\u001b[A\n",
      " 80%|████████  | 1.33M/1.65M [00:10<00:02, 130kB/s]\u001b[A\n",
      " 82%|████████▏ | 1.36M/1.65M [00:10<00:01, 153kB/s]\u001b[A\n",
      " 84%|████████▍ | 1.38M/1.65M [00:10<00:01, 164kB/s]\u001b[A\n",
      " 85%|████████▌ | 1.41M/1.65M [00:10<00:01, 139kB/s]\u001b[A\n",
      " 87%|████████▋ | 1.44M/1.65M [00:10<00:01, 162kB/s]\u001b[A\n",
      " 89%|████████▉ | 1.47M/1.65M [00:10<00:01, 170kB/s]\u001b[A\n",
      " 90%|█████████ | 1.49M/1.65M [00:11<00:01, 143kB/s]\u001b[A\n",
      " 93%|█████████▎| 1.53M/1.65M [00:11<00:00, 173kB/s]\u001b[A\n",
      " 94%|█████████▍| 1.56M/1.65M [00:11<00:00, 176kB/s]\u001b[A\n",
      " 96%|█████████▌| 1.58M/1.65M [00:11<00:00, 187kB/s]\u001b[A\n",
      " 97%|█████████▋| 1.61M/1.65M [00:11<00:00, 189kB/s]\u001b[A\n",
      " 99%|█████████▉| 1.64M/1.65M [00:11<00:00, 210kB/s]\u001b[A\n",
      "\n",
      "0.00B [00:00, ?B/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fjs/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/fjs/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0.00/4.54k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "8.19kB [00:00, 16.9kB/s]                   \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fjs/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.92MB [00:50, 359kB/s]                            \n",
      "1.65MB [00:23, 210kB/s]                            \u001b[A"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('/data/fjs/data', transform=img_transform,download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.1229\n",
      "epoch [2/100], loss:0.1198\n",
      "epoch [3/100], loss:0.1283\n",
      "epoch [4/100], loss:0.1218\n",
      "epoch [5/100], loss:0.1156\n",
      "epoch [6/100], loss:0.1190\n",
      "epoch [7/100], loss:0.1123\n",
      "epoch [8/100], loss:0.1200\n",
      "epoch [9/100], loss:0.1189\n",
      "epoch [10/100], loss:0.1117\n",
      "epoch [11/100], loss:0.1146\n",
      "epoch [12/100], loss:0.1219\n",
      "epoch [13/100], loss:0.1137\n",
      "epoch [14/100], loss:0.1096\n",
      "epoch [15/100], loss:0.1207\n",
      "epoch [16/100], loss:0.1110\n",
      "epoch [17/100], loss:0.1138\n",
      "epoch [18/100], loss:0.1098\n",
      "epoch [19/100], loss:0.1132\n",
      "epoch [20/100], loss:0.1098\n",
      "epoch [21/100], loss:0.1144\n",
      "epoch [22/100], loss:0.1081\n",
      "epoch [23/100], loss:0.1102\n",
      "epoch [24/100], loss:0.1091\n",
      "epoch [25/100], loss:0.1129\n",
      "epoch [26/100], loss:0.1150\n",
      "epoch [27/100], loss:0.1004\n",
      "epoch [28/100], loss:0.1095\n",
      "epoch [29/100], loss:0.1072\n",
      "epoch [30/100], loss:0.1111\n",
      "epoch [31/100], loss:0.0930\n",
      "epoch [32/100], loss:0.1071\n",
      "epoch [33/100], loss:0.1094\n",
      "epoch [34/100], loss:0.0954\n",
      "epoch [35/100], loss:0.1056\n",
      "epoch [36/100], loss:0.1016\n",
      "epoch [37/100], loss:0.0963\n",
      "epoch [38/100], loss:0.1104\n",
      "epoch [39/100], loss:0.1078\n",
      "epoch [40/100], loss:0.1099\n",
      "epoch [41/100], loss:0.1048\n",
      "epoch [42/100], loss:0.1019\n",
      "epoch [43/100], loss:0.1080\n",
      "epoch [44/100], loss:0.1052\n",
      "epoch [45/100], loss:0.1009\n",
      "epoch [46/100], loss:0.0987\n",
      "epoch [47/100], loss:0.1031\n",
      "epoch [48/100], loss:0.1015\n",
      "epoch [49/100], loss:0.0941\n",
      "epoch [50/100], loss:0.1052\n",
      "epoch [51/100], loss:0.1084\n",
      "epoch [52/100], loss:0.1013\n",
      "epoch [53/100], loss:0.1005\n",
      "epoch [54/100], loss:0.0952\n",
      "epoch [55/100], loss:0.1008\n",
      "epoch [56/100], loss:0.1028\n",
      "epoch [57/100], loss:0.1072\n",
      "epoch [58/100], loss:0.1070\n",
      "epoch [59/100], loss:0.1043\n",
      "epoch [60/100], loss:0.0937\n",
      "epoch [61/100], loss:0.0955\n",
      "epoch [62/100], loss:0.0980\n",
      "epoch [63/100], loss:0.1008\n",
      "epoch [64/100], loss:0.1016\n",
      "epoch [65/100], loss:0.0958\n",
      "epoch [66/100], loss:0.0991\n",
      "epoch [67/100], loss:0.0990\n",
      "epoch [68/100], loss:0.1013\n",
      "epoch [69/100], loss:0.1016\n",
      "epoch [70/100], loss:0.0945\n",
      "epoch [71/100], loss:0.0993\n",
      "epoch [72/100], loss:0.1077\n",
      "epoch [73/100], loss:0.0973\n",
      "epoch [74/100], loss:0.1034\n",
      "epoch [75/100], loss:0.1021\n",
      "epoch [76/100], loss:0.1065\n",
      "epoch [77/100], loss:0.1000\n",
      "epoch [78/100], loss:0.0996\n",
      "epoch [79/100], loss:0.0969\n",
      "epoch [80/100], loss:0.1060\n",
      "epoch [81/100], loss:0.0977\n",
      "epoch [82/100], loss:0.1078\n",
      "epoch [83/100], loss:0.0896\n",
      "epoch [84/100], loss:0.1012\n",
      "epoch [85/100], loss:0.0999\n",
      "epoch [86/100], loss:0.0924\n",
      "epoch [87/100], loss:0.1014\n",
      "epoch [88/100], loss:0.0930\n",
      "epoch [89/100], loss:0.1046\n",
      "epoch [90/100], loss:0.1057\n",
      "epoch [91/100], loss:0.0976\n",
      "epoch [92/100], loss:0.1017\n",
      "epoch [93/100], loss:0.0895\n",
      "epoch [94/100], loss:0.0906\n",
      "epoch [95/100], loss:0.0994\n",
      "epoch [96/100], loss:0.0906\n",
      "epoch [97/100], loss:0.1022\n",
      "epoch [98/100], loss:0.0987\n",
      "epoch [99/100], loss:0.1027\n",
      "epoch [100/100], loss:0.1018\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    #if epoch % 10 == 0:\n",
    "        #pic = to_img(output.cpu().data)\n",
    "        #save_image(pic, '/data/fjs/data/dc_img/image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
